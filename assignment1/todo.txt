Q1.a) implement resnet arch --> input n and r

layers --> 6n+2:
            a) 32*32*16 --> 2n + 1
            b) 16*16*32 --> 2n
            c) 8*8*64 --> 2n
            d) final classification layer --> 8 classes --> fully connected


write a resnet code in pytorch with following directions:
1. As- sume that the total number of layers in the network is given by 6n+2. This includes the first hidden (convolution) layer processing the input of size 32×32.

2. This is followed by n layers with feature map size 32×32, fol- lowed by n layers with feature map size 16 × 16, n layers with feature map size given by 8 × 8, and finally a fully connected output layer with r units, r being number of classes.

3. The number of filters in the 3 sets of n hid- den layers (after the first convoluational layer) are 16, 32, 64, respectively. There are residual connections between each block of 2 layers, except for the first convolutional layer and the output layer.

4. All the convolutions use a filter size of 3 × 3 inspired by the VGG net architecture [Simonyan and Zisserman, 2015]. 

5. Whenever down-sampling, we use the convolutional layer with stride of 2. Appropriate zero padding is done at each layer so that there is no change in size due to boundary effects. The final hidden layer does a mean pool over all the features before feeding into the output layer.

6. Your program should take n as input. It should also take r as input denoting the total number of classes.

7. Train the ResNet architecture with n = 2 as described above on the CIFAR 10 dataset. Use a batch size of 128 and train for 100 epochs. For CIFAR 10, r = 10. Use SGD optimizer with initial learning rate of 0.1. Decay or schedule the learning rate as appropriate. Feel free to experiment with different optimizers other than SGD.

8. The train data has 50, 000 images. Randomly select any 10,000 of these as validation data. Use validation data for early stopping. NOTE: DO NOT use test data split at all during the training process. Report the
following statistics / analysis:
•Accuracy, Micro F1 and Macro F1 on Train, Val and Test splits.
•Plot the error curves for both the train and the val data.




1. Implement from scratch the following. They should
be implemented as a sub-class of nn.Module.
(a) Resnet
(b) Group Normalization (GN) [Wu and He, 2020]

